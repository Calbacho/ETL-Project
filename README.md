# W4 Project - ETL Project
ETL para proyecto de predicciÃ³n de accidentes de trÃ¡fico en Madrid

![portada](https://github.com/Calbacho/ETL-Project/blob/main/img/trafico.jpg)

## â›“ï¸ Ãndice
[1. ğŸ” Objetivo](#objetivo)\
[2.ğŸš¨ HistÃ³rico de accidentes](#accidentes)\
[3.ğŸš¦ Puntos de medida](#puntos)\
[4.ğŸš˜ HistÃ³rico de trÃ¡fico](#trafico)\
[5.âœ… Carga](#carga)\
[6.ğŸ”² PrÃ³ximos pasos](#carga)

<a name="objetivo"/>

## ğŸ” Objetivo

Fase **ETL** para proyecto de predicciÃ³n de accidentes de trÃ¡fico en Madrid segÃºn estadÃ­sticas macro como la localizaciÃ³n, el momento, las condiciones de trÃ¡fico y las condiciones meteorolÃ³gicas.

**ExtracciÃ³n:**
- HistÃ³rico de accidentes
- Puntos de medida
- HistÃ³rico de trÃ¡fico

**Limpieza:**
- Nulos
- Duplicados
- Consistencia
- Fromato
- Nuevas columnas

**Carga:**
- A mi disco duro
- A SQL
- A GitHub

<a name="accidentes"/>

## ğŸš¨ HistÃ³rico de accidentes

10 CSVs con los accidentes cada aÃ±o
```
acc_2013 = pd.read_csv('2013_Accidentalidad.csv', sep = ';', encoding="ISO-8859-1")
```

### Columnas

**Â¿CuÃ¡ndo?** Fecha, Hora, DÃ­a de la semana

**Â¿DÃ³nde?** Distrito, LocalizaciÃ³n, Coordenadas

**Â¿Gravedad?** Ileso, Leve, Grave, Fallecidos...

**Â¿Condiciones?** MeteorologÃ­a

### Limpieza

- Nulos
- Duplicados
- Consistencia
- Fromato
- Nuevas columnas


```
345176 rows Ã— 10 columns
```


**Â¿PodrÃ­a encontrar el nivel de trÃ¡fico antes del accidente?**

<a name="puntos"/>

## ğŸš¦ Puntos de medida

<details>
<summary>Â¿QuÃ© son?</summary>
<br>

Estos sistemas de detecciÃ³n son, en su mayorÃ­a, lazos electromagnÃ©ticos que se colocan
debajo del pavimento y detectan la masa metÃ¡lica de los vehÃ­culos que pasan sobre ellos,
siendo sistemas de gran calidad y precisiÃ³n.
  
![lazo](https://github.com/Calbacho/ETL-Project/blob/main/img/lazo.jpg)

</details>

<details>
<summary>Â¿QuÃ© miden?</summary>
<br>

**1. Intensidad:** NÂº de vehÃ­culos en los Ãºltimos 15 minutos

**2. OcupaciÃ³n:** Porcentage de vÃ­a ocupada por vehÃ­culos en los Ãºltimos 15 minutos
  
**3. Velocidad media** en los Ãºltimos 15 minutos

</details>

<details>
<summary>Â¿DÃ³nde estÃ¡n?</summary>
<br>

![geo_ejem](https://github.com/Calbacho/ETL-Project/blob/main/img/geo_ejem.png)

```
geo_trackers = pd.read_csv('pmed_ubicacion_12-2022.csv', sep = ';', on_bad_lines='skip')
```

<img src="https://github.com/Calbacho/ETL-Project/blob/main/img/tabla_geos.png" width="300" height="300" />

</details>




<a name="trafico"/>

## ğŸš˜ HistÃ³rico de trÃ¡fico

**Web Scrapping** para navegar por url, descargar 96 zips y extraerlos a csv.

**Vaex** para leer cada CSV, concatenarlo por aÃ±o, limpiar cada aÃ±o y generar tabla histÃ³rica.

<details>
<summary>CÃ“DIGO</summary>
<br>


#### Abrir pÃ¡gina web
  
```
driver.get(url)

time.sleep(2)
```
  
#### Aceptar cookies
  
```
cookies = driver.find_element(By.XPATH, '//*[@id="iam-cookie-control-modal-action-primary"]')

try:
    cookies.click()
except:
    pass

time.sleep(2)
```
  
#### Ir a pÃ¡gina con todos los zips

```
enlaces = driver.find_element(By.XPATH, '//*[@id="readspeaker"]/div[3]/div/div[1]/div/a')

try:
    enlaces.click()
except:
    pass

time.sleep(2)
```
 
#### Meter los enlaces a zips en una lista

```
links = driver.find_elements(By.XPATH, '//*[@id="readspeaker"]/div[3]/div/div[1]/ul/li/ul/li/ul/li/a')[:96]

urls  = []

for i in links:
    urls.append(i.get_attribute('href'))
```
  
#### Descargar y extraer

```
for i in urls:
    
    count += 1
    
    r = requests.get(i)
    z = zipfile.ZipFile(io.BytesIO(r.content))
    z.extractall('zips')
```

#### Convertir a formato Vaex

```
path = os.getcwd()

csv_files = glob.glob(os.path.join(path + '\\zips', "*.csv"))


for i in csv_files:

    df_temp = vaex.from_csv(i, sep = ';', convert = True, chunk_size = 5_000_000, on_bad_lines='skip', low_memory=False) 
```

#### Abrir por aÃ±o y concatenar

```
df_2015 = vaex.open('C:\\Users\\calba\\OneDrive\\Desktop\\zips\\01-2015.csv.hdf5')

vaex_files = glob.glob(os.path.join(path + '\\zips', "*.hdf5"))

for i in vaex_files[0::8][1:-1]:
    df = vaex.open(i)
    
    df_2015 = df_2015.concat(df)
```

</details>

```
1159303428 rows Ã— 6 columns
```

<a name="carga"/>

## âœ… Carga

- A mi disco duro
- A SQL
<img src="https://github.com/Calbacho/ETL-Project/blob/main/img/sql_acc.png" width="450" height="450" />

- A GitHub

<a name="pasos"/>

## ğŸ”² PrÃ³ximos pasos

1. **Enriquecimiento** de los datos - Â¿Viento? Â¿Discotecas cercanas? Â¿Colegios cercanos? Â¿Eventos?
2. **AnÃ¡lisis descriptivo** de los datos
3. **ML** modelo de predicciÃ³n


